{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/Project_Gen/blob/main/SurgicalGPT%2B%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvn6yKZCMHhU"
      },
      "source": [
        "Downlaod code and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p3dRC8LKXUN",
        "outputId": "9c5bd605-1c0d-4ee5-ef05-c2aa9c93ffce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Project_Gen'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 41 (delta 16), reused 27 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (41/41), 16.95 KiB | 4.24 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n",
            "/content/Project_Gen/datasets\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WGdztykX3nW6pi_BKp4rO8nA7ESNRfVN\n",
            "To: /content/Project_Gen/datasets/EndoVis-18-VQA.zip\n",
            "100% 2.70G/2.70G [00:25<00:00, 108MB/s] \n",
            "/content/Project_Gen\n"
          ]
        }
      ],
      "source": [
        "#Download code\n",
        "!git clone https://github.com/mobarakol/Project_Gen.git\n",
        "!mkdir /content/Project_Gen/datasets\n",
        "%cd /content/Project_Gen/datasets\n",
        "\n",
        "#Download Dataset\n",
        "!gdown --id 1WGdztykX3nW6pi_BKp4rO8nA7ESNRfVN\n",
        "\n",
        "# Unzipping the VQA EndoVis18 Dataset\\\n",
        "!unzip -q EndoVis-18-VQA.zip\n",
        "\n",
        "%cd /content/Project_Gen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2RoeUOhPErX"
      },
      "source": [
        "Installing requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvA3l8GpPG7y",
        "outputId": "a444534f-27e9-4114-cf06-e632b1136de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLSnki7sPIfM"
      },
      "source": [
        "Running Script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdqD0wzeOnoP",
        "outputId": "8ed8759c-2886-41b1-fcb6-3d5fb3013af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Project_Gen\n",
            "2023-11-04 03:10:55.637928: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-04 03:10:55.637987: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-04 03:10:55.638029: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-04 03:10:57.071864: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "efvlegpt2rs18 v1 zeroes m18 1e-05 checkpoints/efvlegpt2rs18/m18_v1_z_qf_\n",
            "device = cuda\n",
            "Downloading (…)olve/main/vocab.json: 100% 1.04M/1.04M [00:00<00:00, 4.24MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 35.8MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 5.34MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 665/665 [00:00<00:00, 3.17MB/s]\n",
            "Total files: 1560 | Total question: 10574\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Total files: 447 | Total question: 3216\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 99.3MB/s]\n",
            "Downloading model.safetensors: 100% 548M/548M [00:01<00:00, 291MB/s]\n",
            "Downloading (…)neration_config.json: 100% 124/124 [00:00<00:00, 605kB/s]\n",
            "model params:  174607680\n",
            "100% 265/265 [07:12<00:00,  1.63s/it]\n",
            "Epoch: 1/80 Loss: 1.081118 AVG_Loss: 2.031560\n",
            "100% 81/81 [02:07<00:00,  1.57s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "Epoch: 1/80 EVA LOSS: 0.885475 BLEU-1 0.184842 BLEU2 0.078755 BLEU3 0.007000 BLEU-4 0.000000\n",
            "100% 265/265 [07:05<00:00,  1.60s/it]\n",
            "Epoch: 2/80 Loss: 0.568340 AVG_Loss: 0.827513\n",
            "100% 81/81 [02:12<00:00,  1.64s/it]\n",
            "Epoch: 2/80 EVA LOSS: 0.334290 BLEU-1 0.453341 BLEU2 0.366114 BLEU3 0.276066 BLEU-4 0.193694\n",
            " 15% 40/265 [01:12<04:16,  1.14s/it]"
          ]
        }
      ],
      "source": [
        "%cd /content/Project_Gen\n",
        "import os\n",
        "os.makedirs('checkpoints/efvlegpt2rs18', exist_ok=True)\n",
        "!python train_SGPT_V2_Sentence.py \\\n",
        "--lr=0.00001 \\\n",
        "--checkpoint_dir='checkpoints/efvlegpt2rs18/m18_v1_z_qf_' \\\n",
        "--dataset_type='m18' \\\n",
        "--tokenizer_ver='gpt2v1' \\\n",
        "--model_ver='efvlegpt2rs18' \\\n",
        "--model_subver='v1' \\\n",
        "--vis_pos_emb='zeroes'\\\n",
        "--batch_size=40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48GwkJQvPArS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPx4f+6N4amlwvu9XePTDqg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}